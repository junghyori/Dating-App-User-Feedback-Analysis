{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "31b766d3",
   "metadata": {},
   "source": [
    "## Summary on the Method and Output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d73e7aca",
   "metadata": {},
   "source": [
    "The topic modelling analysis identified 10 topics in a dataset of user feedback or reviews about a dating app. Specific features that users would like to see improved are extracted, based on a list of keywords related to improvement. This can help the product team prioritize and address specific user concerns or pain points in order to improve the user experience and drive engagement on the platform. Each topic represents a common theme or issue that users have with the app, such as technical issues, dating experience, user interface, security, and account management.\n",
    "\n",
    "These results suggest that the app's user experience may be a critical area for improvement, with specific focus on messaging functionality, swiping and user interface, and addressing user concerns related to privacy and account management. Additionally, the analysis highlights the importance of addressing concerns related to fraudulent activity and security, as well as optimizing the app's technical performance to ensure a smooth user experience.\n",
    "\n",
    "Overall, the results of the topic modelling can provide valuable insights for the product team, helping them to identify areas for improvement and optimize the app's design and functionality to better meet user needs and preferences."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bff62f49",
   "metadata": {},
   "source": [
    "## Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "af077966",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package vader_lexicon to\n",
      "[nltk_data]     /Users/ijeonghyeon/nltk_data...\n",
      "[nltk_data]   Package vader_lexicon is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/ijeonghyeon/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/ijeonghyeon/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/ijeonghyeon/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import string\n",
    "import re\n",
    "import contractions\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from textblob import TextBlob\n",
    "import requests, time\n",
    "from nltk.sentiment import SentimentIntensityAnalyzer\n",
    "\n",
    "\n",
    "nltk.download('vader_lexicon')\n",
    "nltk.download(\"stopwords\")\n",
    "nltk.download(\"wordnet\")\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "126ac031",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"bumble_google_play_reviews.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5ba425df",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 126724 entries, 0 to 126723\n",
      "Data columns (total 10 columns):\n",
      " #   Column                Non-Null Count   Dtype \n",
      "---  ------                --------------   ----- \n",
      " 0   reviewId              126724 non-null  object\n",
      " 1   userName              126724 non-null  object\n",
      " 2   userImage             126724 non-null  object\n",
      " 3   content               126715 non-null  object\n",
      " 4   score                 126724 non-null  int64 \n",
      " 5   thumbsUpCount         126724 non-null  int64 \n",
      " 6   reviewCreatedVersion  105867 non-null  object\n",
      " 7   at                    126724 non-null  object\n",
      " 8   replyContent          82340 non-null   object\n",
      " 9   repliedAt             82340 non-null   object\n",
      "dtypes: int64(2), object(8)\n",
      "memory usage: 9.7+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fb455c9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "print(df.duplicated().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4d9917c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reviewId                    0\n",
      "userName                    0\n",
      "userImage                   0\n",
      "content                     9\n",
      "score                       0\n",
      "thumbsUpCount               0\n",
      "reviewCreatedVersion    20857\n",
      "at                          0\n",
      "replyContent            44384\n",
      "repliedAt               44384\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(df.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5c49873b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                                                Great\n",
       "1                                    Why am i blocked?\n",
       "2                                            good work\n",
       "3                                              cool ap\n",
       "4                                                  Wow\n",
       "5    I've been on it for a day and let me tell you ...\n",
       "6                                              Useless\n",
       "7    I am serious about dating, but even when Bumbl...\n",
       "8    Just rating for the most godawful ads you have...\n",
       "9    20 people like me apparently. been a week of d...\n",
       "Name: content, dtype: object"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = df[\"content\"]\n",
    "\n",
    "text[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "10ca8179",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a list of negation cues\n",
    "negation_cues = [\"not\", \"n't\", \"never\", \"no\", \"none\", \"neither\", \"nor\"]\n",
    "\n",
    "def text_preprocessing(text):\n",
    "    # Convert to lowercase\n",
    "    text = str(text)\n",
    "    text = text.lower()\n",
    "    # Remove punctuation\n",
    "    text = text.translate(str.maketrans(\"\", \"\", string.punctuation))\n",
    "    # Tokenize the text\n",
    "    text_tokens = nltk.word_tokenize(text)\n",
    "    # Handle negation cues\n",
    "    negated = False\n",
    "    for i, token in enumerate(text_tokens):\n",
    "        if token.lower() in negation_cues:\n",
    "            negated = True\n",
    "        elif negated:\n",
    "            text_tokens[i] = \"NOT_\" + token\n",
    "            negated = False\n",
    "    # Remove stop words\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    filtered_text = [word for word in text_tokens if not word in stop_words]\n",
    "    # Join the filtered words back into a string\n",
    "    text = ' '.join(filtered_text)\n",
    "    # Replace contractions with their expanded form\n",
    "    text = contractions.fix(text)\n",
    "    return text\n",
    "\n",
    "processed_text = []\n",
    "for text in text:\n",
    "    result = text_preprocessing(text)\n",
    "    processed_text.append(result)\n",
    "    \n",
    "processed_text = pd.Series(processed_text)\n",
    "\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "# Define a function that takes a sentence as input and returns a list of lemmas\n",
    "def lemmatize_nltk(sentence):\n",
    "    tokens = nltk.word_tokenize(sentence)\n",
    "    # Perform part-of-speech tagging on the tokens \n",
    "    pos_tags = nltk.pos_tag(tokens)\n",
    "    lemmas = []\n",
    "    for token, tag in pos_tags:\n",
    "        # Map the POS tag to the corresponding WordNet POS tag\n",
    "        tag = get_wordnet_pos(tag)\n",
    "        if tag:\n",
    "            lemma = lemmatizer.lemmatize(token, tag)\n",
    "        else:\n",
    "            lemma = lemmatizer.lemmatize(token)\n",
    "        lemmas.append(lemma)\n",
    "    return lemmas\n",
    "\n",
    "# Define a function that maps NLTK POS tags to WordNet POS tags\n",
    "def get_wordnet_pos(tag):\n",
    "    if tag.startswith('N'):\n",
    "        return 'n'\n",
    "    elif tag.startswith('V'):\n",
    "        return 'v'\n",
    "    elif tag.startswith('J'):\n",
    "        return 'a'\n",
    "    elif tag.startswith('R'):\n",
    "        return 'r'\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "lemmatized_words = []\n",
    "for sentence in processed_text:\n",
    "    lemmas = lemmatize_nltk(sentence)\n",
    "    lemmatized_words.append(lemmas)\n",
    "    \n",
    "# Convert the list of lemmatized words to a Series\n",
    "lemmatised_text = pd.Series(lemmatized_words)\n",
    "\n",
    "lemmatised_text.head()\n",
    "\n",
    "lemmatised_corpus = []\n",
    "\n",
    "for doc in lemmatised_text:\n",
    "    sentence = \" \".join(doc)\n",
    "    lemmatised_corpus.append(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "71850a18",
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews = lemmatised_corpus"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53971e73",
   "metadata": {},
   "source": [
    "## Topic Modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "24a327db",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.corpora import Dictionary\n",
    "\n",
    "tokenized_corpus = [nltk.word_tokenize(doc) for doc in lemmatised_corpus]\n",
    "dictionary = Dictionary(tokenized_corpus)\n",
    "dictionary.filter_extremes(no_below=2, no_above=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "91960d4d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic: 1 \n",
      "Words: 0.141*\"app\" + 0.122*\"not\" + 0.068*\"do\" + 0.040*\"message\" + 0.036*\"time\" + 0.032*\"work\" + 0.031*\"make\" + 0.030*\"first\" + 0.024*\"guy\" + 0.023*\"girl\"\n",
      "Topic: 2 \n",
      "Words: 0.105*\"woman\" + 0.073*\"great\" + 0.069*\"tinder\" + 0.053*\"well\" + 0.053*\"date\" + 0.040*\"concept\" + 0.038*\"love\" + 0.032*\"apps\" + 0.031*\"easy\" + 0.029*\"men\"\n",
      "Topic: 3 \n",
      "Words: 0.129*\"swipe\" + 0.064*\"right\" + 0.048*\"day\" + 0.038*\"show\" + 0.036*\"pretty\" + 0.036*\"much\" + 0.026*\"leave\" + 0.025*\"yet\" + 0.019*\"android\" + 0.018*\"already\"\n",
      "Topic: 4 \n",
      "Words: 0.051*\"would\" + 0.037*\"keep\" + 0.035*\"give\" + 0.028*\"every\" + 0.026*\"connection\" + 0.026*\"hour\" + 0.025*\"fix\" + 0.024*\"actually\" + 0.024*\"let\" + 0.022*\"thing\"\n",
      "Topic: 5 \n",
      "Words: 0.171*\"profile\" + 0.089*\"fake\" + 0.071*\"lot\" + 0.043*\"could\" + 0.041*\"picture\" + 0.039*\"sign\" + 0.038*\"though\" + 0.025*\"fun\" + 0.024*\"best\" + 0.020*\"location\"\n",
      "Topic: 6 \n",
      "Words: 0.107*\"account\" + 0.105*\"back\" + 0.056*\"delete\" + 0.041*\"bad\" + 0.040*\"change\" + 0.036*\"NOT_a\" + 0.034*\"anything\" + 0.034*\"photo\" + 0.033*\"email\" + 0.030*\"ask\"\n",
      "Topic: 7 \n",
      "Words: 0.202*\"like\" + 0.091*\"facebook\" + 0.061*\"see\" + 0.042*\"also\" + 0.032*\"take\" + 0.031*\"pay\" + 0.029*\"week\" + 0.026*\"backtrack\" + 0.023*\"feature\" + 0.016*\"bug\"\n",
      "Topic: 8 \n",
      "Words: 0.071*\"match\" + 0.068*\"be\" + 0.060*\"get\" + 0.056*\"i\" + 0.046*\"people\" + 0.045*\"use\" + 0.034*\"have\" + 0.024*\"go\" + 0.021*\"one\" + 0.021*\"bumble\"\n",
      "Topic: 9 \n",
      "Words: 0.171*\"good\" + 0.048*\"user\" + 0.041*\"notification\" + 0.035*\"maybe\" + 0.029*\"attractive\" + 0.028*\"contact\" + 0.027*\"tell\" + 0.025*\"5\" + 0.024*\"star\" + 0.023*\"wish\"\n",
      "Topic: 10 \n",
      "Words: 0.063*\"nice\" + 0.052*\"update\" + 0.051*\"nothing\" + 0.043*\"issue\" + 0.040*\"reply\" + 0.026*\"fb\" + 0.024*\"model\" + 0.023*\"last\" + 0.023*\"review\" + 0.023*\"enough\"\n"
     ]
    }
   ],
   "source": [
    "from gensim.models import LdaModel\n",
    "\n",
    "# create a bag of words corpus\n",
    "bow_corpus = [dictionary.doc2bow(doc) for doc in tokenized_corpus]\n",
    "\n",
    "# build the LDA model with 5 topics\n",
    "num_topics = 10\n",
    "lda_model = LdaModel(corpus=bow_corpus,\n",
    "                     id2word=dictionary,\n",
    "                     num_topics=num_topics,\n",
    "                     random_state=42,\n",
    "                     update_every=1,\n",
    "                     chunksize=100,\n",
    "                     passes=10,\n",
    "                     alpha='auto',\n",
    "                     per_word_topics=True)\n",
    "\n",
    "# print the topics and their top 10 keywords\n",
    "for idx, topic in lda_model.print_topics(-1):\n",
    "    print('Topic: {} \\nWords: {}'.format(idx+1, topic))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5a2cd66",
   "metadata": {},
   "source": [
    "### Additional analysis and insights for each of the topics in the given list\n",
    "\n",
    "- Topic 1: This topic suggests that users are experiencing issues with the app's messaging functionality, as well as other technical problems. This could be a critical issue for the business, as messaging is a core feature of most dating apps, and technical issues could drive users away from the platform. Improving the app's messaging and technical performance could be a key priority for the product team.\n",
    "\n",
    "\n",
    "- Topic 2: This topic suggests that users are using the app for dating, and may be looking for specific features or functionality to support their dating goals. For example, they may be interested in features that make it easy to find and connect with other users, or to filter potential matches based on certain criteria. Understanding user needs and preferences in this area could help the product team develop new features or improve existing ones to better support the user experience.\n",
    "\n",
    "\n",
    "- Topic 3: This topic suggests that users may be frustrated with the app's swiping functionality or other user interface elements. This could be a key area for improvement, as the app's user interface is a critical component of the user experience. The product team may need to conduct user testing or research to better understand user needs and preferences, and use this information to inform the design and development of the app's user interface.\n",
    "\n",
    "\n",
    "- Topic 4: This topic suggests that users may be experiencing connection issues or other technical problems that are preventing them from using the app effectively. Addressing these issues could be a key priority for the product team, as they could significantly impact user retention and engagement. The team may need to conduct technical audits or engage with users to identify and address these issues.\n",
    "\n",
    "\n",
    "- Topic 5: This topic suggests that users are concerned about fake profiles and other fraudulent activity on the platform. This could be a critical issue for the business, as users are likely to abandon the platform if they do not feel that their safety and privacy are being protected. The product team may need to develop new security features or improve existing ones to better address these concerns.\n",
    "\n",
    "\n",
    "- Topic 6: This topic suggests that users may be concerned about account management and privacy issues. The product team may need to improve the app's privacy settings or develop new features to help users better manage their accounts and data. This could be a critical area of focus for the business, as privacy concerns are a key driver of user trust and engagement.\n",
    "\n",
    "\n",
    "- Topic 7: This topic suggests that users may be interested in social media integration or other advanced features that enhance the user experience. The product team may need to conduct user research or testing to better understand user needs and preferences in this area, and use this information to inform the design and development of new features.\n",
    "\n",
    "\n",
    "- Topic 8: This topic suggests that users have general feedback or comments about the app, and may be interested in a range of different features or functionality. The product team may need to engage with users to better understand their needs and preferences, and use this information to guide product development and optimization.\n",
    "\n",
    "\n",
    "- Topic 9: This topic suggests that users are generally satisfied with the app's performance and features, but may have minor complaints or issues. The product team may need to prioritize bug fixes or other optimizations to ensure that the app continues to meet user expectations and remains competitive in the market.\n",
    "\n",
    "\n",
    "- Topic 10: This topic suggests that users may be experiencing issues with app updates or other technical issues. The product team may need to prioritize technical support or other resources to help users resolve these issues and ensure that they are able to use the app effectively. Improving user support and engagement could be critical for driving user retention and engagement."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
